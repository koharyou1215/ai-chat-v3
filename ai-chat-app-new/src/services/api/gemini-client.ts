// import { GoogleGenerativeAI } from "@google/generative-ai";

// const API_KEY = process.env.GEMINI_API_KEY || '';

// File system operations - Node.js only

// Gemini API ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
export interface GeminiMessage {
  role: "user" | "model";
  parts: Array<{ text: string }>;
}

export interface GeminiRequest {
  contents: GeminiMessage[];
  generationConfig?: {
    temperature?: number;
    topP?: number;
    topK?: number;
    maxOutputTokens?: number;
    stopSequences?: string[];
  };
  safetySettings?: Array<{
    category: string;
    threshold: string;
  }>;
}

export interface GeminiResponse {
  candidates: Array<{
    content: {
      parts: Array<{ text: string }>;
      role: string;
    };
    finishReason: string;
    index: number;
    safetyRatings: Array<{
      category: string;
      probability: string;
    }>;
  }>;
  promptFeedback: {
    safetyRatings: Array<{
      category: string;
      probability: string;
    }>;
  };
}

export class GeminiClient {
  private apiKey: string;
  private openRouterApiKey: string;
  private baseURL: string;
  private model: string;
  private openRouterModelsCache: { models: string[]; timestamp: number } | null = null;
  private openRouterModelsCacheTTL = 60 * 60 * 1000; // 1æ™‚é–“ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥

  constructor() {
    this.apiKey = "";
    this.openRouterApiKey = "";
    this.baseURL = "https://generativelanguage.googleapis.com/v1beta/models";
    this.model = "gemini-2.5-flash"; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…¬å¼ã®gemini-2.5-flash
    this.initializeApiKeySync();
  }

  // ãƒ¢ãƒ‡ãƒ«åã®æ­£è¦åŒ–ï¼ˆãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ä½¿ç”¨ï¼‰
  private normalizeModelName(modelName: string): string {
    // ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«åã®è‡ªå‹•ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    const { migrateModelName } = require('@/utils/model-migration');
    const migration = migrateModelName(modelName);
    
    if (migration.wasLegacy && migration.message) {
      console.warn(`ğŸš¨ ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«æ¤œå‡º: ${migration.message}`);
    }
    
    // google/ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ã—ã¦è¿”ã™ï¼ˆGemini APIç”¨ï¼‰
    return migration.migratedModel.replace('google/', '');
  }

  // ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
  setModel(modelName: string): void {
    // ãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–
    this.model = this.normalizeModelName(modelName);
    console.log("ğŸŒŸ Gemini model set to:", this.model);
  }

  private initializeApiKeySync(): void {
    // ç’°å¢ƒå¤‰æ•°ã‹ã‚‰åŒæœŸçš„ã«APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰å„ªå…ˆï¼‰
    const apiKey =
      process.env.GEMINI_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY;
    if (apiKey) {
      this.apiKey = apiKey;
      // Gemini API Key loaded from environment variable (sync)
    } else {
      console.warn(
        "âŒ GEMINI_API_KEY or NEXT_PUBLIC_GEMINI_API_KEY not found, API calls will fail"
      );
    }

    // OpenRouter API ã‚­ãƒ¼ã‚‚åˆæœŸåŒ–ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    const openRouterKey =
      process.env.OPENROUTER_API_KEY ||
      process.env.NEXT_PUBLIC_OPENROUTER_API_KEY;
    if (openRouterKey) {
      this.openRouterApiKey = openRouterKey;
      // OpenRouter API Key loaded for Gemini fallback
    }
  }

  // æ˜ç¤ºçš„ãªåˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå¿…è¦æ™‚ã®ã¿ä½¿ç”¨ï¼‰
  async initialize(): Promise<void> {
    try {
      if (!this.apiKey) {
        this.apiKey = await this.loadApiKeyFromFile();
        console.log("Gemini API key initialized successfully (async)");
      }
    } catch (error) {
      console.error("Failed to initialize API key:", error);
      throw error;
    }
  }

  private async loadApiKeyFromFile(): Promise<string> {
    try {
      // ç’°å¢ƒå¤‰æ•°ã‚’æœ€åˆã«ç¢ºèªï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰å„ªå…ˆï¼‰
      const apiKey =
        process.env.GEMINI_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY;
      if (apiKey) {
        // Gemini API Key loaded from environment variable
        return apiKey;
      }

      // ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒã§ã¯ç’°å¢ƒå¤‰æ•°ã®ã¿ä½¿ç”¨
      if (typeof window !== "undefined") {
        throw new Error(
          "GEMINI_API_KEY ã¾ãŸã¯ NEXT_PUBLIC_GEMINI_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒï¼‰"
        );
      }

      // ã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒã§ã®ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
      if (typeof window === "undefined") {
        try {
          const fs = await import("fs");
          const path = await import("path");
          const keyPath = path.default.join(
            process.cwd(),
            "gemini-api-key.txt"
          );
          const fileApiKey = fs.default.readFileSync(keyPath, "utf-8").trim();

          if (!fileApiKey) {
            throw new Error("GeminiAPIã‚­ãƒ¼ãŒç©ºã§ã™");
          }

          console.log("Gemini API Key loaded from file");
          return fileApiKey;
        } catch (fileError) {
          console.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ã‚‚å¤±æ•—:", fileError);
          throw new Error(
            "GEMINI_API_KEY ã¾ãŸã¯ NEXT_PUBLIC_GEMINI_API_KEY ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯gemini-api-key.txtãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™"
          );
        }
      }
      
      // This should never be reached, but TypeScript needs it
      throw new Error("API key could not be loaded");
    } catch (error) {
      console.error("GeminiAPIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—:", error);
      throw error;
    }
  }

  async generateMessage(
    messages: GeminiMessage[],
    options?: {
      temperature?: number;
      maxTokens?: number;
      topP?: number;
      topK?: number;
      model?: string;
      useDirectGeminiAPI?: boolean; // è¨­å®šã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    }
  ): Promise<string> {
    // ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ™‚çš„ã«ä¸Šæ›¸ãã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ï¼ˆã‚¹ã‚³ãƒ¼ãƒ—ã‚’é–¢æ•°å…¨ä½“ã«æ‹¡å¼µï¼‰
    const modelToUse = options?.model
      ? this.normalizeModelName(options.model)
      : this.model;

    // Gemini APIç›´æ¥ä½¿ç”¨ãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯trueï¼‰
    const useDirectAPI = options?.useDirectGeminiAPI ?? true;

    // OpenRouterçµŒç”±ã‚’å¼·åˆ¶ã™ã‚‹å ´åˆ
    if (!useDirectAPI && this.openRouterApiKey) {
      console.log('ğŸš€ Using OpenRouter directly for Gemini (bypassing Gemini API)');
      return await this.generateViaOpenRouter(messages, {
        ...options,
        model: modelToUse
      });
    }

    try {
      // API key validation
      if (!this.apiKey) {
        console.error("Gemini API key is not set");
        await this.initialize(); // Try to initialize if not done
        if (!this.apiKey) {
          // Gemini APIã‚­ãƒ¼ãŒãªã„å ´åˆã€OpenRouterã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
          if (this.openRouterApiKey) {
            // No Gemini API key, using OpenRouter fallback
            return await this.generateViaOpenRouter(messages, {
              ...options,
              model: modelToUse
            });
          }
          throw new Error(
            "Gemini API key is not available. Please check GEMINI_API_KEY or NEXT_PUBLIC_GEMINI_API_KEY environment variable."
          );
        }
      }

      console.log("ğŸ”— Gemini API Request:", {
        model: modelToUse,
        messageCount: messages.length,
        hasApiKey: !!this.apiKey,
      });

      const request: GeminiRequest = {
        contents: messages,
        generationConfig: {
          temperature: options?.temperature ?? 0.7,
          topP: options?.topP ?? 0.9,
          topK: options?.topK ?? 40,
          maxOutputTokens: options?.maxTokens ?? 2048,
        },
        safetySettings: [
          {
            category: "HARM_CATEGORY_HARASSMENT",
            threshold: "BLOCK_NONE",
          },
          {
            category: "HARM_CATEGORY_HATE_SPEECH",
            threshold: "BLOCK_NONE",
          },
          {
            category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold: "BLOCK_NONE",
          },
          {
            category: "HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold: "BLOCK_NONE",
          },
        ],
      };

      const url = `${this.baseURL}/${modelToUse}:generateContent?key=${this.apiKey}`;

      const response = await fetch(url, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify(request),
      });

      if (!response.ok) {
        let errorMessage = response.statusText;
        try {
          const errorData = await response.json();
          errorMessage = errorData.error?.message || errorMessage;
        } catch (parseError) {
          console.error('Failed to parse error response:', parseError);
        }
        throw new Error(`Gemini API error: ${errorMessage}`);
      }

      const data: GeminiResponse = await response.json();

      if (!data.candidates || data.candidates.length === 0) {
        throw new Error("No candidates returned from Gemini API");
      }

      const candidate = data.candidates[0];
      console.log("Gemini API Response:", JSON.stringify(data, null, 2));

      if (
        !candidate.content ||
        !candidate.content.parts ||
        candidate.content.parts.length === 0
      ) {
        console.error("Gemini candidate details:", candidate);

        // Handle different finish reasons appropriately
        if (candidate.finishReason === "MAX_TOKENS") {
          console.warn("Gemini response truncated due to token limit");
          return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé•·ã™ãã¦åˆ‡ã‚Šè©°ã‚ã‚‰ã‚Œã¾ã—ãŸã€‚ã‚ˆã‚ŠçŸ­ã„å…¥åŠ›ã§ãŠè©¦ã—ãã ã•ã„ã€‚";
        } else if (candidate.finishReason === "SAFETY") {
          throw new Error("Gemini response blocked by safety filters");
        } else if (candidate.finishReason === "RECITATION") {
          throw new Error("Gemini response blocked due to recitation concerns");
        } else if (candidate.finishReason) {
          throw new Error(
            `Gemini response blocked. Reason: ${candidate.finishReason}`
          );
        }

        throw new Error("No content parts in Gemini response");
      }

      return candidate.content.parts[0].text;
    } catch (error) {
      console.error("Gemini message generation failed:", error);

      // ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã®ã¿OpenRouterãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è©¦è¡Œ
      if (this.isQuotaOrRateLimitError(error)) {
        console.log(
          "ğŸ”„ Quota/Rate limit detected, attempting fallback via OpenRouter..."
        );
        
        // OpenRouter APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if (!this.openRouterApiKey) {
          console.error("OpenRouter API key not configured for fallback");
          throw new Error(
            "Gemini APIã®ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚è¨­å®šç”»é¢ã§OpenRouter APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚"
          );
        }
        
        try {
          // è¨­å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«æ¸¡ã™
          const fallbackOptions = {
            ...options,
            model: options?.model || modelToUse,
          };
          return await this.generateViaOpenRouter(messages, fallbackOptions);
        } catch (fallbackError) {
          console.error("OpenRouter fallback also failed:", fallbackError);
          
          const fallbackErrorMsg = fallbackError instanceof Error 
            ? fallbackError.message 
            : "Unknown error";
          
          // OpenRouterã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºã‚’æä¾›
          if (fallbackErrorMsg.includes("401") || fallbackErrorMsg.includes("Unauthorized")) {
            throw new Error(
              "OpenRouter APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚è¨­å®šã§æ­£ã—ã„APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
            );
          }
          
          throw new Error(
            `Gemini APIã®ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚OpenRouterãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—ã—ã¾ã—ãŸ: ${fallbackErrorMsg}`
          );
        }
      }

      // ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯ãã®ã¾ã¾æŠ•ã’ã‚‹
      throw error;
    }
  }

  // OpenRouterçµŒç”±ã§Geminiã‚’å‘¼ã³å‡ºã™
  private async generateViaOpenRouter(
    messages: GeminiMessage[],
    options?: {
      temperature?: number;
      maxTokens?: number;
      topP?: number;
      topK?: number;
      model?: string;
    }
  ): Promise<string> {
    if (!this.openRouterApiKey) {
      throw new Error('OpenRouter API key not found for fallback. Please set OpenRouter API key.');
    }

    const openRouterMessages = messages.map((msg) => ({
      role: msg.role === 'model' ? 'assistant' : msg.role,
      content: msg.parts[0].text,
    }));

    // ãƒ¢ãƒ‡ãƒ«åã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    const { migrateModelName } = require('@/utils/model-migration');
    const originalModel = options?.model || this.model;
    const migration = migrateModelName(originalModel);
    
    if (migration.wasLegacy) {
      console.warn(`ğŸš¨ OpenRouterãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã«ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«æ¤œå‡º: ${migration.message}`);
    }
    
    const fallbackModel = migration.migratedModel; // ã™ã§ã« google/ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ã

    if (originalModel !== fallbackModel) {
      // Model conversion applied
    }
    // Using OpenRouter fallback

    const available = await this.fetchOpenRouterModels();
    let chosenModel = fallbackModel;
    if (!available.includes(fallbackModel)) {
      const candidates = [
        fallbackModel,
        'google/gemini-2.5-flash',
        'google/gemini-2.5-pro',
        'google/gemini-2.5-flash-lite',
        'openai/gpt-4o-mini',
        'openai/gpt-4o',
        'anthropic/claude-3-5-sonnet',
      ];

      const found = candidates.find((c) => available.includes(c));
      if (found) {
        // OpenRouter mapped model not present, switching to available model
        chosenModel = found;
      } else {
        throw new Error(`No supported OpenRouter model available for fallback (tried: ${candidates.join(', ')})`);
      }
    }

    // Try request with a simple retry
    let lastError: any = null;
    for (let attempt = 1; attempt <= 2; attempt++) {
      try {
        const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
          method: 'POST',
          headers: {
            Authorization: `Bearer ${this.openRouterApiKey}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': process.env.VERCEL_URL || 'http://localhost:3000',
            'X-Title': 'AI Chat V3',
          },
          body: JSON.stringify({
            model: chosenModel,
            messages: openRouterMessages,
            temperature: options?.temperature ?? 0.7,
            max_tokens: options?.maxTokens ?? 2048,
            top_p: options?.topP ?? 0.9,
          }),
        });

        if (!response.ok) {
          let errorMessage = response.statusText;
          try {
            const errorData = await response.json();
            errorMessage = errorData.error?.message || errorMessage;
            
            // ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«IDã‚¨ãƒ©ãƒ¼ã®å ´åˆã€åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if (errorMessage.includes('is not a valid model') || 
                errorMessage.includes('not a valid model ID') || 
                errorMessage.includes('model not found') ||
                errorMessage.includes('does not exist')) {
              console.warn(`âš ï¸ Invalid model ${chosenModel}, attempting fallback to default model`);
              // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œï¼ˆå†å¸°å‘¼ã³å‡ºã—ã‚’é¿ã‘ã‚‹ãŸã‚ç›´æ¥è¨­å®šï¼‰
              if (chosenModel !== 'google/gemini-2.5-flash') {
                chosenModel = 'google/gemini-2.5-flash';
                // Retrying with fallback model
                continue; // ãƒ«ãƒ¼ãƒ—ã‚’ç¶šè¡Œã—ã¦å†è©¦è¡Œ
              }
            }
          } catch (parseError) {
            console.error('Failed to parse error response:', parseError);
          }
          throw new Error(`OpenRouter API error: ${errorMessage}`);
        }

        const data = await response.json();
        return data.choices[0].message.content;
      } catch (err) {
        lastError = err;
        if (attempt === 1) await new Promise((r) => setTimeout(r, 300));
      }
    }

    throw lastError;
  }

  // Fetch available model ids from OpenRouter for runtime validation with caching.
  private async fetchOpenRouterModels(): Promise<string[]> {
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã¯è¿”ã™
    if (this.openRouterModelsCache && 
        Date.now() - this.openRouterModelsCache.timestamp < this.openRouterModelsCacheTTL) {
      // Using cached OpenRouter models list
      return this.openRouterModelsCache.models;
    }

    if (!this.openRouterApiKey) {
      throw new Error('OpenRouter API key not found for model discovery');
    }

    // Fetching fresh OpenRouter models list
    const resp = await fetch('https://openrouter.ai/api/v1/models', {
      headers: {
        Authorization: `Bearer ${this.openRouterApiKey}`,
        'HTTP-Referer': process.env.VERCEL_URL || 'http://localhost:3000',
        'X-Title': 'AI Chat V3',
      },
    });

    if (!resp.ok) {
      let text = resp.statusText;
      try {
        const body = await resp.text();
        text = body || text;
      } catch (_) {}
      throw new Error(`OpenRouter models API error: ${resp.status} ${text}`);
    }

    const body = await resp.json();
    const models = Array.isArray(body?.data) ? body.data.map((m: any) => m.id).filter(Boolean) : [];
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    this.openRouterModelsCache = {
      models,
      timestamp: Date.now()
    };
    
    // Cached OpenRouter models
    return models;
  }

  async generateMessageStream(
    messages: GeminiMessage[],
    onChunk: (chunk: string) => void,
    options?: {
      temperature?: number;
      maxTokens?: number;
      topP?: number;
      topK?: number;
      model?: string;
    }
  ): Promise<string> {
    // ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ™‚çš„ã«ä¸Šæ›¸ãã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
    const modelToUse = options?.model
      ? this.normalizeModelName(options.model)
      : this.model;
    
    try {
      const request: GeminiRequest = {
        contents: messages,
        generationConfig: {
          temperature: options?.temperature ?? 0.7,
          topP: options?.topP ?? 0.9,
          topK: options?.topK ?? 40,
          maxOutputTokens: options?.maxTokens ?? 2048,
        },
        safetySettings: [
          {
            category: "HARM_CATEGORY_HARASSMENT",
            threshold: "BLOCK_NONE",
          },
          {
            category: "HARM_CATEGORY_HATE_SPEECH",
            threshold: "BLOCK_NONE",
          },
          {
            category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold: "BLOCK_NONE",
          },
          {
            category: "HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold: "BLOCK_NONE",
          },
        ],
      };

        const url = `${this.baseURL}/${modelToUse}:streamGenerateContent?key=${this.apiKey}`;

        const response = await fetch(url, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(request),
        });

        if (!response.ok) {
          let errorMessage = response.statusText;
          try {
            const errorData = await response.json();
            errorMessage = errorData.error?.message || errorMessage;
          } catch (parseError) {
            console.error('Failed to parse error response:', parseError);
          }
          throw new Error(`Gemini API error: ${errorMessage}`);
        }

        const reader = response.body?.getReader();
      if (!reader) {
        throw new Error("Response body is not readable");
      }

      let fullContent = "";
      const decoder = new TextDecoder();

      try {
        while (true) {
          const { done, value } = await reader.read();

          if (done) break;

          const chunk = decoder.decode(value);
          const lines = chunk.split("\n");

          for (const line of lines) {
            if (line.startsWith("data: ")) {
              try {
                const jsonData = JSON.parse(line.slice(6));
                if (
                  jsonData.candidates &&
                  jsonData.candidates[0]?.content?.parts?.[0]?.text
                ) {
                  const text = jsonData.candidates[0].content.parts[0].text;
                  fullContent += text;
                  onChunk(text);
                }
              } catch (_parseError) {
                // JSON parsing error - skip this chunk
                continue;
              }
            }
          }
        }
      } finally {
        reader.releaseLock();
      }

      return fullContent;
    } catch (error) {
      console.error("Gemini streaming generation failed:", error);
      throw error;
    }
  }

  setApiKey(apiKey: string): void {
    this.apiKey = apiKey;
    // Gemini API key set dynamically
  }

  setOpenRouterApiKey(apiKey: string): void {
    this.openRouterApiKey = apiKey;
    // OpenRouter API key set for Gemini fallback
  }

  /**
   * ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã‚„ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š
   */
  private isQuotaOrRateLimitError(error: any): boolean {
    if (!error || !error.message) return false;

    const errorMessage = error.message.toLowerCase();
    return (
      errorMessage.includes("quota exceeded") ||
      errorMessage.includes("rate limit") ||
      errorMessage.includes("too many requests") ||
      errorMessage.includes("requests per minute") ||
      errorMessage.includes("resource_exhausted") ||
      errorMessage.includes("429")
    );
  }

  getAvailableModels(): string[] {
  // Only expose the three allowed models
  return ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-2.5-flash-lite"];
  }

  formatMessagesForGemini(
    systemPrompt: string,
    userMessage: string,
    conversationHistory: Array<{
      role: "user" | "assistant";
      content: string;
    }> = []
  ): GeminiMessage[] {
    const messages: GeminiMessage[] = [];

    // ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«çµ±åˆ
    let firstMessage = "";
    if (systemPrompt.trim()) {
      firstMessage = `${systemPrompt}\n\n`;
    }

    // ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆè‹±èªæ··ã˜ã‚Šã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰
    for (const msg of conversationHistory) {
      // ä¼šè©±å±¥æ­´ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼šè‹±èªæ··ã˜ã‚Šã®æ–‡ã‚’ä¿®æ­£
      const cleanedContent = this.cleanHistoryContent(msg.content);
      messages.push({
        role: msg.role === "assistant" ? "model" : "user",
        parts: [{ text: cleanedContent }],
      });
    }

    // ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ï¼ˆåˆå›ã®å ´åˆã¯ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚å«ã‚ã‚‹ï¼‰
    const finalUserMessage =
      conversationHistory.length === 0
        ? firstMessage + userMessage
        : userMessage;
    messages.push({
      role: "user",
      parts: [{ text: finalUserMessage }],
    });

    console.log("=== Gemini Messages Debug ===");
    console.log("System prompt:", systemPrompt.substring(0, 100) + "...");
    console.log("Conversation history length:", conversationHistory.length);
    console.log("Final messages:", JSON.stringify(messages, null, 2));
    console.log("==============================");

    return messages;
  }

  /**
   * ä¼šè©±å±¥æ­´ã®å†…å®¹ã‹ã‚‰è‹±èªæ··ã˜ã‚Šã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
   */
  private cleanHistoryContent(content: string): string {
    // ã‚ˆãæ··å…¥ã™ã‚‹è‹±èªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ—¥æœ¬èªã«ç½®æ›
    const replacements: Record<string, string> = {
      ' and ': 'ã¨',
      ' but ': 'ã—ã‹ã—',
      ' or ': 'ã¾ãŸã¯',
      ' so ': 'ã ã‹ã‚‰',
      ' because ': 'ãªãœãªã‚‰',
      ' What': 'ä½•',
      'there': 'ãã“',
      'ã‚ãªãŸ and ': 'ã‚ãªãŸã¨',
      'ã§ã™ and ': 'ã§ã™ã—',
    };

    let cleaned = content;
    Object.entries(replacements).forEach(([eng, jpn]) => {
      const pattern = new RegExp(eng, 'gi');
      cleaned = cleaned.replace(pattern, jpn);
    });

    // ç‹¬ç«‹ã—ãŸè‹±å˜èªã‚’æ¤œå‡ºã—ã¦å‰Šé™¤ï¼ˆå›ºæœ‰åè©ã‚’é™¤ãï¼‰
    cleaned = cleaned.replace(
      /\b([a-z]{2,})\b/gi,
      (match) => {
        // å›ºæœ‰åè©ï¼ˆæœ€åˆãŒå¤§æ–‡å­—ã§çŸ­ã„ï¼‰ã¯æ®‹ã™
        if (match[0] === match[0].toUpperCase() && match.length <= 10) {
          return match;
        }
        return '';
      }
    );

    // é€£ç¶šã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤
    cleaned = cleaned.replace(/\s+/g, ' ').trim();
    
    return cleaned;
  }
}

export const geminiClient = new GeminiClient();
