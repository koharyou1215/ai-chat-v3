/**
 * AI Chat V3 Voice Server
 * GPU VPSç”¨ é«˜æ€§èƒ½éŸ³å£°é€šè©±ã‚µãƒ¼ãƒãƒ¼
 */

const WebSocket = require('ws');
const express = require('express');
const http = require('http');
const https = require('https');
const fs = require('fs');
const axios = require('axios');
const VAD = require('node-vad'); // VADã‚’æœ‰åŠ¹åŒ–
const { v4: uuidv4 } = require('uuid');
const cors = require('cors');

class VoiceCallServer {
  constructor(options = {}) {
    this.port = options.port || 8080;
    this.httpsPort = options.httpsPort || 8443;
    this.voicevoxUrl = process.env.VOICEVOX_ENGINE_URL || 'http://localhost:50021';
    this.openaiApiKey = process.env.OPENAI_API_KEY;
    this.geminiApiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;
    this.elevenLabsApiKey = process.env.ELEVENLABS_API_KEY;
    
    // Sessionsç®¡ç†
    this.sessions = new Map();
    this.audioCache = new Map();
    this.maxCacheSize = 200;
    
    // éŸ³å£°è¨­å®š
    this.sampleRate = 16000;
    this.frameDurationMs = 20;
    this.silenceThresholdMs = 1500; // 1.5ç§’ã«å»¶é•·
    
    this.initializeServer();
  }

  initializeServer() {
    // Express ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
    this.app = express();
    this.app.use(cors());
    this.app.use(express.json());
    
    // ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    this.app.get('/health', (req, res) => {
      res.json({
        status: 'healthy',
        timestamp: new Date().toISOString(),
        sessions: this.sessions.size,
        cache: this.audioCache.size
      });
    });
    
    // VOICEVOX ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    this.app.get('/voicevox/health', async (req, res) => {
      try {
        const response = await axios.get(`${this.voicevoxUrl}/version`, {
          timeout: 5000
        });
        res.json({
          status: 'healthy',
          voicevox: response.data,
          endpoint: this.voicevoxUrl
        });
      } catch (error) {
        res.status(503).json({
          status: 'error',
          error: error.message,
          endpoint: this.voicevoxUrl
        });
      }
    });

    // HTTPã‚µãƒ¼ãƒãƒ¼ä½œæˆ
    this.server = http.createServer(this.app);
    
    // HTTPS ã‚µãƒ¼ãƒãƒ¼ï¼ˆSSLè¨¼æ˜æ›¸ãŒã‚ã‚‹å ´åˆï¼‰
    this.setupHttpsServer();
    
    // WebSocketã‚µãƒ¼ãƒãƒ¼
    this.wss = new WebSocket.Server({ 
      server: this.server,
      perMessageDeflate: false,
      clientTracking: true
    });
    
    this.setupWebSocketHandlers();
    this.startServer();
  }

  setupHttpsServer() {
    try {
      // SSLè¨¼æ˜æ›¸ã®ãƒ‘ã‚¹ï¼ˆLet's Encryptã®å ´åˆï¼‰
      const privateKey = fs.readFileSync('/etc/letsencrypt/live/your-domain.com/privkey.pem', 'utf8');
      const certificate = fs.readFileSync('/etc/letsencrypt/live/your-domain.com/cert.pem', 'utf8');
      const ca = fs.readFileSync('/etc/letsencrypt/live/your-domain.com/chain.pem', 'utf8');

      const credentials = {
        key: privateKey,
        cert: certificate,
        ca: ca
      };

      this.httpsServer = https.createServer(credentials, this.app);
      this.wssSecure = new WebSocket.Server({ 
        server: this.httpsServer,
        perMessageDeflate: false,
        clientTracking: true
      });
      
      // HTTPS WebSocket ã‚‚åŒã˜ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ä½¿ç”¨
      this.setupWebSocketHandlers(this.wssSecure);
      
    } catch (error) {
      console.log('HTTPS server setup skipped (SSL certificates not found)');
    }
  }

  setupWebSocketHandlers(wss = this.wss) {
    wss.on('connection', (ws, req) => {
      const sessionId = uuidv4();
      const clientIp = req.socket.remoteAddress;
      
      console.log(`[${new Date().toISOString()}] New voice session: ${sessionId} from ${clientIp}`);
      
      // ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
      const session = {
        id: sessionId,
        ws,
        clientIp,
        audioBuffer: [],
        isProcessing: false,
        lastSpeechTime: 0,
        conversationHistory: [],
        vad: new VAD(VAD.Mode.AGGRESSIVE), // VADåˆæœŸåŒ–
        responseQueue: [],
        isPlayingResponse: false,
        startTime: Date.now(),
        stats: {
          messagesReceived: 0,
          audioProcessed: 0,
          errorsOccurred: 0
        }
      };
      
      this.sessions.set(sessionId, session);
      
      // æ¥ç¶šç¢ºç«‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
      this.sendMessage(ws, {
        type: 'session_start',
        sessionId,
        config: {
          sampleRate: this.sampleRate,
          frameSize: this.frameDurationMs,
          serverTime: Date.now()
        }
      });
      
      // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
      ws.on('message', async (data) => {
        session.stats.messagesReceived++;
        
        try {
          if (data instanceof Buffer) {
            // éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            await this.handleAudioData(sessionId, data);
          } else {
            // JSONãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
            const message = JSON.parse(data.toString());
            await this.handleControlMessage(sessionId, message);
          }
        } catch (error) {
          console.error(`[${sessionId}] Message handling error:`, error);
          session.stats.errorsOccurred++;
        }
      });
      
      // åˆ‡æ–­ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
      ws.on('close', (code, reason) => {
        const duration = Date.now() - session.startTime;
        console.log(`[${sessionId}] Session closed: ${code} ${reason} (duration: ${duration}ms)`);
        console.log(`[${sessionId}] Stats:`, session.stats);
        this.sessions.delete(sessionId);
      });
      
      // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
      ws.on('error', (error) => {
        console.error(`[${sessionId}] WebSocket error:`, error);
        session.stats.errorsOccurred++;
        this.sessions.delete(sessionId);
      });
    });
  }

  async handleAudioData(sessionId, audioData) {
    const session = this.sessions.get(sessionId);
    if (!session || session.isProcessing) return;

    try {
      // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
      if (!audioData || audioData.length === 0) {
        return;
      }

      // VADã§éŸ³å£°åŒºé–“æ¤œå‡º
      const isSpeech = await this.detectSpeech(audioData, session.vad);
      const currentTime = Date.now();
      
      const chunk = {
        timestamp: currentTime,
        data: audioData,
        isSpeech
      };
      
      if (isSpeech) {
        // éŸ³å£°æ¤œå‡ºæ™‚
        session.audioBuffer.push(chunk);
        session.lastSpeechTime = currentTime;
        
        this.sendMessage(session.ws, {
          type: 'voice_activity',
          status: 'speaking',
          timestamp: currentTime
        });
        
      } else if (
        session.lastSpeechTime > 0 && 
        currentTime - session.lastSpeechTime > 500 && // 500ms ã®ç„¡éŸ³ã§ç™ºè©±çµ‚äº†
        session.audioBuffer.length > 0 &&
        !session.isProcessing
      ) {
        // ç™ºè©±çµ‚äº†æ¤œå‡º
        session.isProcessing = true;
        
        this.sendMessage(session.ws, {
          type: 'voice_activity',
          status: 'processing',
          timestamp: currentTime
        });
        
        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        const completeAudio = Buffer.concat(
          session.audioBuffer.map(chunk => chunk.data)
        );
        
        console.log(`[${sessionId}] ğŸ¤ Processing ${session.audioBuffer.length} audio chunks (${completeAudio.length} bytes)`);
        
        // ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢
        session.audioBuffer = [];
        session.lastSpeechTime = 0;
        session.stats.audioProcessed++;
        
        // éåŒæœŸã§éŸ³å£°å‡¦ç†é–‹å§‹
        setImmediate(() => this.processUtterance(sessionId, completeAudio));
      }
      
    } catch (error) {
      console.error(`[${sessionId}] Audio processing error:`, error);
      session.stats.errorsOccurred++;
    }
  }

  // VADéŸ³å£°æ¤œå‡ºï¼ˆå®‰å…¨ç‰ˆï¼‰
  async detectSpeech(audioData, vad) {
    return new Promise((resolve) => {
      if (!vad) {
        resolve(true); // VADãŒç„¡åŠ¹ã®å ´åˆã¯å¸¸ã«éŸ³å£°ã¨ã—ã¦æ‰±ã†
        return;
      }

      try {
        // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦VADã®å‡¦ç†ã«é©ã—ãŸã‚µã‚¤ã‚ºã«èª¿æ•´
        if (audioData.length < 32) {
          resolve(false); // ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã‚‹å ´åˆã¯ç„¡éŸ³ã¨ã—ã¦æ‰±ã†
          return;
        }

        // VADãŒæœŸå¾…ã™ã‚‹ã‚µã‚¤ã‚ºï¼ˆ16bitã‚µãƒ³ãƒ—ãƒ«ï¼‰ã«èª¿æ•´
        const expectedSize = Math.floor(audioData.length / 2) * 2;
        const adjustedBuffer = audioData.slice(0, expectedSize);

        vad.processAudio(adjustedBuffer, 16000, (err, res) => {
          if (err) {
            console.error('VAD error:', err);
            resolve(false); // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç„¡éŸ³ã¨ã—ã¦æ‰±ã†ï¼ˆéŸ³å£°å‡¦ç†ã‚’åœæ­¢ï¼‰
          } else {
            resolve(res === VAD.Event.VOICE);
          }
        });
      } catch (error) {
        console.error('VAD processing error:', error);
        resolve(false); // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç„¡éŸ³ã¨ã—ã¦æ‰±ã†
      }
    });
  }

  async handleControlMessage(sessionId, message) {
    const session = this.sessions.get(sessionId);
    if (!session) return;

    console.log(`[${sessionId}] Received control message:`, message.type);

    switch (message.type) {
      case 'ping':
        this.sendMessage(session.ws, {
          type: 'pong',
          timestamp: Date.now()
        });
        console.log(`[${sessionId}] Pong sent`);
        break;
        
      case 'test':
        this.sendMessage(session.ws, {
          type: 'test_response',
          message: 'Hello from voice server!',
          timestamp: Date.now()
        });
        console.log(`[${sessionId}] Test response sent`);
        break;
        
      case 'clear_history':
        session.conversationHistory = [];
        this.sendMessage(session.ws, {
          type: 'history_cleared',
          timestamp: Date.now()
        });
        break;
        
      case 'get_stats':
        this.sendMessage(session.ws, {
          type: 'stats',
          stats: session.stats,
          timestamp: Date.now()
        });
        break;
        
      case 'stop_audio':
        // éŸ³å£°å‡¦ç†ã‚’å³åº§ã«åœæ­¢
        session.isProcessing = false;
        session.audioBuffer = [];
        console.log(`[${sessionId}] Audio processing stopped and buffers cleared`);
        
        this.sendMessage(session.ws, {
          type: 'audio_stopped',
          timestamp: Date.now()
        });
        break;
    }
  }

  async processUtterance(sessionId, audioData) {
    const session = this.sessions.get(sessionId);
    if (!session) return;

    try {
      // 1. éŸ³å£°èªè­˜
      const text = await this.speechToText(audioData);
      
      if (!text || text.trim().length === 0) {
        session.isProcessing = false;
        return;
      }
      
      console.log(`[${sessionId}] èªè­˜: "${text}"`);
      
      // èªè­˜çµæœé€ä¿¡
      this.sendMessage(session.ws, {
        type: 'transcription',
        text,
        timestamp: Date.now()
      });
      
      // 2. å¿œç­”ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
      let fullResponse = '';
      let currentSentence = '';
      
      const responseStream = this.generateResponseStream(text, session);
      
      for await (const chunk of responseStream) {
        if (!chunk) continue;
        
        currentSentence += chunk;
        fullResponse += chunk;
        
        // æ–‡åŒºåˆ‡ã‚Šã§éŸ³å£°åˆæˆ
        if (this.isSentenceEnd(currentSentence)) {
          const sentence = currentSentence.trim();
          if (sentence) {
            // éŸ³å£°åˆæˆã‚’ä¸¦åˆ—å®Ÿè¡Œ
            setImmediate(() => this.synthesizeAndSend(sessionId, sentence));
            currentSentence = '';
          }
        }
      }
      
      // æ®‹ã‚Šãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
      if (currentSentence.trim()) {
        await this.synthesizeAndSend(sessionId, currentSentence.trim());
      }
      
      // AIå¿œç­”ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
      this.sendMessage(session.ws, {
        type: 'ai_response',
        text: fullResponse,
        timestamp: Date.now()
      });

      // ä¼šè©±å±¥æ­´æ›´æ–°
      session.conversationHistory.push(
        { role: 'user', content: text },
        { role: 'assistant', content: fullResponse }
      );
      
      // å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
      if (session.conversationHistory.length > 20) {
        session.conversationHistory = session.conversationHistory.slice(-20);
      }
      
    } catch (error) {
      console.error(`[${sessionId}] Processing error:`, error);
      session.stats.errorsOccurred++;
      
      this.sendMessage(session.ws, {
        type: 'error',
        message: 'Processing failed',
        timestamp: Date.now()
      });
      
    } finally {
      session.isProcessing = false;
    }
  }

  async speechToText(audioData) {
    // Gemini APIã‚’å„ªå…ˆã—ã¦ä½¿ç”¨
    if (this.geminiApiKey && this.geminiApiKey !== 'YOUR_GEMINI_API_KEY_HERE') {
      return await this.speechToTextWithGemini(audioData);
    }
    
    // OpenAI Whisper APIã‚’ä½¿ç”¨  
    if (this.openaiApiKey && this.openaiApiKey.startsWith('sk-')) {
      return await this.speechToTextWithWhisper(audioData);
    }
    
    // ãƒ†ã‚¹ãƒˆç”¨ãƒ¢ãƒƒã‚¯å¿œç­”ï¼ˆä¸€å›ã ã‘ï¼‰
    console.log('ğŸ§ª APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã€ãƒ†ã‚¹ãƒˆå¿œç­”ã‚’è¿”ã—ã¾ã™');
    return 'ã“ã‚“ã«ã¡ã¯ã€éŸ³å£°é€šè©±ã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚';
  }

  async speechToTextWithGemini(audioData) {
    try {
      // Geminiã§ã¯ç¾åœ¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´æ¥å‡¦ç†ã¯ã§ããªã„ãŸã‚ã€
      // ãƒ†ã‚¹ãƒˆç”¨ã«å›ºå®šå¿œç­”ã‚’è¿”ã™ï¼ˆä¸€å›ã ã‘ï¼‰
      console.log('ğŸ¤– Geminiã‚’ä½¿ç”¨ã—ãŸéŸ³å£°å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ');
      return 'Geminiã«ã‚ˆã‚‹éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆã§ã™ã€‚';
    } catch (error) {
      console.error('Gemini Speech-to-Text Error:', error);
      return 'GeminiéŸ³å£°èªè­˜ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚';
    }
  }

  async speechToTextWithWhisper(audioData) {

    try {
      const wavBuffer = this.addWavHeader(audioData);
      
      const formData = new FormData();
      formData.append('file', new Blob([wavBuffer], { type: 'audio/wav' }), 'audio.wav');
      formData.append('model', 'whisper-1');
      formData.append('language', 'ja');
      formData.append('prompt', 'è‡ªç„¶ãªæ—¥æœ¬èªã§ã®ä¼šè©±ã§ã™ã€‚');
      formData.append('temperature', '0.2');
      
      const response = await axios.post(
        'https://api.openai.com/v1/audio/transcriptions',
        formData,
        {
          headers: {
            'Authorization': `Bearer ${this.openaiApiKey}`,
            'Content-Type': 'multipart/form-data'
          },
          timeout: 10000
        }
      );
      
      return response.data.text || '';
      
    } catch (error) {
      console.error('STT Error:', error.message);
      return '';
    }
  }

  async* generateResponseStream(text, session) {
    // Gemini APIã‚’å„ªå…ˆã—ã¦ä½¿ç”¨
    if (this.geminiApiKey && this.geminiApiKey !== 'YOUR_GEMINI_API_KEY_HERE') {
      yield* this.generateResponseWithGemini(text, session);
      return;
    }
    
    // OpenAI APIã‚’ä½¿ç”¨
    if (this.openaiApiKey && this.openaiApiKey.startsWith('sk-')) {
      yield* this.generateResponseWithOpenAI(text, session);
      return;
    }
    
    // ãƒ†ã‚¹ãƒˆç”¨ãƒ¢ãƒƒã‚¯å¿œç­”
    console.log('ğŸ§ª APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã€ãƒ†ã‚¹ãƒˆå¿œç­”ã‚’è¿”ã—ã¾ã™');
    yield `äº†è§£ã—ã¾ã—ãŸã€‚ã€Œ${text}ã€ã§ã™ã­ã€‚éŸ³å£°åˆæˆã®ãƒ†ã‚¹ãƒˆã‚’è¡Œã„ã¾ã™ã€‚`;
  }

  async* generateResponseWithGemini(text, session) {
    try {
      console.log('ğŸ¤– Geminiã§å¿œç­”ç”Ÿæˆä¸­...');
      
      // Gemini APIã‚’ä½¿ç”¨ã—ãŸå¿œç­”ç”Ÿæˆ
      const response = await axios.post(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${this.geminiApiKey}`,
        {
          contents: [
            {
              parts: [
                {
                  text: `ã‚ãªãŸã¯è¦ªåˆ‡ã§è‡ªç„¶ãªä¼šè©±ãŒã§ãã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
éŸ³å£°é€šè©±ã§ã®ä¼šè©±ãªã®ã§ã€ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¿”ç­”ï¼ˆ1-2æ–‡ç¨‹åº¦ï¼‰ã‚’ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€: "${text}"

è‡ªç„¶ãªæ—¥æœ¬èªã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚`
                }
              ]
            }
          ],
          generationConfig: {
            temperature: 0.8,
            maxOutputTokens: 100,
            topP: 0.95
          }
        },
        {
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );
      
      const responseText = response.data?.candidates?.[0]?.content?.parts?.[0]?.text || 'ã™ã¿ã¾ã›ã‚“ã€ã†ã¾ãèã“ãˆã¾ã›ã‚“ã§ã—ãŸã€‚';
      console.log(`ğŸ¤– Geminiå¿œç­”: "${responseText}"`);
      yield responseText;
      
    } catch (error) {
      console.error('Gemini Generation Error:', error);
      yield 'ã™ã¿ã¾ã›ã‚“ã€å°‘ã—èª¿å­ãŒæ‚ªã„ã‚ˆã†ã§ã™ã€‚ã‚‚ã†ä¸€åº¦ãŠè©±ã—ãã ã•ã„ã€‚';
    }
  }

  async* generateResponseWithOpenAI(text, session) {

    try {
      const messages = [
        {
          role: 'system',
          content: `ã‚ãªãŸã¯è¦ªåˆ‡ã§è‡ªç„¶ãªä¼šè©±ãŒã§ãã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
éŸ³å£°é€šè©±ã§ã®ä¼šè©±ãªã®ã§ã€ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š

- ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¿”ç­”
- è‡ªç„¶ãªæ—¥æœ¬èªã§ã®å¿œç­”
- é©åº¦ãªæ„Ÿæƒ…è¡¨ç¾
- é•·ã™ããªã„æ–‡ç« ï¼ˆ1-2æ–‡ç¨‹åº¦ï¼‰
- ä¼šè©±ã®ãƒ†ãƒ³ãƒã‚’é‡è¦–`
        },
        ...session.conversationHistory.slice(-10),
        { role: 'user', content: text }
      ];
      
      const response = await axios.post(
        'https://api.openai.com/v1/chat/completions',
        {
          model: 'gpt-3.5-turbo',
          messages,
          temperature: 0.8,
          max_tokens: 150,
          stream: true,
          presence_penalty: 0.6,
          frequency_penalty: 0.3
        },
        {
          headers: {
            'Authorization': `Bearer ${this.openaiApiKey}`,
            'Content-Type': 'application/json'
          },
          responseType: 'stream',
          timeout: 15000
        }
      );
      
      for await (const chunk of response.data) {
        const lines = chunk.toString().split('\n');
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            if (data === '[DONE]') return;
            
            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              if (content) yield content;
            } catch (e) {
              // JSON parse error, skip
            }
          }
        }
      }
      
    } catch (error) {
      console.error('Generation Error:', error.message);
      yield 'ã™ã¿ã¾ã›ã‚“ã€ã‚‚ã†ä¸€åº¦ãŠèã‹ã›ãã ã•ã„ã€‚';
    }
  }

  async synthesizeAndSend(sessionId, text) {
    const session = this.sessions.get(sessionId);
    if (!session || !text.trim()) return;

    try {
      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
      const cacheKey = `tts_${text.trim()}_voicevox`;
      let audioData = this.audioCache.get(cacheKey);
      
      if (!audioData) {
        try {
          // ã¾ãšVOICEVOXã§è©¦è¡Œ
          audioData = await this.synthesizeWithVoicevox(text);
          console.log(`[${sessionId}] TTS Success: VOICEVOX`);
        } catch (voicevoxError) {
          console.warn(`[${sessionId}] VOICEVOX failed, falling back to ElevenLabs:`, voicevoxError.message);
          
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ElevenLabs
          try {
            audioData = await this.synthesizeWithElevenLabs(text);
            console.log(`[${sessionId}] TTS Success: ElevenLabs`);
          } catch (elevenLabsError) {
            console.error(`[${sessionId}] ElevenLabs also failed:`, elevenLabsError.message);
            throw new Error('All TTS services failed');
          }
        }
        
        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        if (this.audioCache.size < this.maxCacheSize) {
          this.audioCache.set(cacheKey, audioData);
        } else {
          // å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
          const firstKey = this.audioCache.keys().next().value;
          this.audioCache.delete(firstKey);
          this.audioCache.set(cacheKey, audioData);
        }
      }
      
      // éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡
      await this.streamAudioToClient(session, audioData);
      
    } catch (error) {
      console.error(`[${sessionId}] TTS Error:`, error.message);
      
      // æœ€çµ‚çš„ãªã‚¨ãƒ©ãƒ¼é€šçŸ¥
      this.sendMessage(session.ws, {
        type: 'tts_error',
        message: 'All audio synthesis services failed',
        text,
        timestamp: Date.now()
      });
    }
  }

  async synthesizeWithVoicevox(text) {
    try {
      // 1. éŸ³å£°ã‚¯ã‚¨ãƒªä½œæˆ
      const queryResponse = await axios.post(
        `${this.voicevoxUrl}/audio_query`,
        null,
        {
          params: {
            text: text.trim(),
            speaker: 1
          },
          timeout: 5000
        }
      );
      
      const audioQuery = queryResponse.data;
      
      // é€Ÿåº¦èª¿æ•´ï¼ˆå°‘ã—æ—©ã‚ã«ï¼‰
      audioQuery.speedScale = 1.15;
      audioQuery.intonationScale = 1.1;
      
      // 2. éŸ³å£°åˆæˆ
      const synthesisResponse = await axios.post(
        `${this.voicevoxUrl}/synthesis`,
        audioQuery,
        {
          params: { speaker: 1 },
          responseType: 'arraybuffer',
          timeout: 10000
        }
      );
      
      return Buffer.from(synthesisResponse.data);
      
    } catch (error) {
      console.error('VOICEVOX Error:', error.message);
      throw error;
    }
  }

  async synthesizeWithElevenLabs(text) {
    if (!this.elevenLabsApiKey) {
      throw new Error('ElevenLabs API key not configured');
    }

    try {
      const response = await axios.post(
        'https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM',
        {
          text: text.trim(),
          model_id: 'eleven_multilingual_v2',
          voice_settings: {
            stability: 0.5,
            similarity_boost: 0.75,
            style: 0.0,
            use_speaker_boost: true
          }
        },
        {
          headers: {
            'Accept': 'audio/mpeg',
            'Content-Type': 'application/json',
            'xi-api-key': this.elevenLabsApiKey
          },
          responseType: 'arraybuffer',
          timeout: 15000
        }
      );
      
      return Buffer.from(response.data);
      
    } catch (error) {
      console.error('ElevenLabs Error:', error.message);
      throw error;
    }
  }

  async streamAudioToClient(session, audioData) {
    const chunkSize = 2048;
    const chunkDelay = 8; // ms
    
    // éŸ³å£°é–‹å§‹é€šçŸ¥
    this.sendMessage(session.ws, {
      type: 'audio_start',
      size: audioData.length,
      timestamp: Date.now()
    });
    
    // ãƒãƒ£ãƒ³ã‚¯é€ä¿¡
    for (let i = 0; i < audioData.length; i += chunkSize) {
      if (session.ws.readyState !== WebSocket.OPEN) break;
      
      const chunk = audioData.slice(i, Math.min(i + chunkSize, audioData.length));
      session.ws.send(chunk, { binary: true });
      
      // é©åº¦ãªé…å»¶ã§ãƒãƒƒãƒ•ã‚¡ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢
      if (i + chunkSize < audioData.length) {
        await new Promise(resolve => setTimeout(resolve, chunkDelay));
      }
    }
    
    // éŸ³å£°çµ‚äº†é€šçŸ¥
    this.sendMessage(session.ws, {
      type: 'audio_end',
      timestamp: Date.now()
    });
  }

  sendMessage(ws, message) {
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify(message));
    }
  }

  isSentenceEnd(text) {
    const sentenceEnders = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ã€', 'ï¼', '\n'];
    return sentenceEnders.some(ender => text.endsWith(ender));
  }

  addWavHeader(audioData) {
    const wavHeader = Buffer.alloc(44);
    const dataSize = audioData.length;
    const fileSize = dataSize + 36;
    
    // RIFF header
    wavHeader.write('RIFF', 0);
    wavHeader.writeUInt32LE(fileSize, 4);
    wavHeader.write('WAVE', 8);
    
    // fmt subchunk
    wavHeader.write('fmt ', 12);
    wavHeader.writeUInt32LE(16, 16);
    wavHeader.writeUInt16LE(1, 20);
    wavHeader.writeUInt16LE(1, 22);
    wavHeader.writeUInt32LE(this.sampleRate, 24);
    wavHeader.writeUInt32LE(this.sampleRate * 2, 28);
    wavHeader.writeUInt16LE(2, 32);
    wavHeader.writeUInt16LE(16, 34);
    
    // data subchunk
    wavHeader.write('data', 36);
    wavHeader.writeUInt32LE(dataSize, 40);
    
    return Buffer.concat([wavHeader, audioData]);
  }

  startServer() {
    this.server.listen(this.port, () => {
      console.log(`ğŸ¤ Voice Server listening on port ${this.port}`);
      console.log(`ğŸ”Š VOICEVOX endpoint: ${this.voicevoxUrl}`);
      console.log(`ğŸ’¾ Cache size limit: ${this.maxCacheSize}`);
    });
    
    if (this.httpsServer) {
      this.httpsServer.listen(this.httpsPort, () => {
        console.log(`ğŸ”’ Secure Voice Server listening on port ${this.httpsPort}`);
      });
    }
    
    // ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
    process.on('SIGTERM', () => this.shutdown());
    process.on('SIGINT', () => this.shutdown());
  }

  shutdown() {
    console.log('ğŸ›‘ Shutting down voice server...');
    
    // å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‰ã˜ã‚‹
    for (const [sessionId, session] of this.sessions) {
      session.ws.close(1001, 'Server shutdown');
    }
    
    // ã‚µãƒ¼ãƒãƒ¼ã‚’é–‰ã˜ã‚‹
    this.server.close(() => {
      console.log('âœ… Voice server shutdown complete');
      process.exit(0);
    });
    
    if (this.httpsServer) {
      this.httpsServer.close();
    }
  }

  // çµ±è¨ˆæƒ…å ±å–å¾—
  getStats() {
    return {
      activeSessions: this.sessions.size,
      cacheSize: this.audioCache.size,
      uptime: process.uptime(),
      memoryUsage: process.memoryUsage(),
      timestamp: new Date().toISOString()
    };
  }
}

// ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
const voiceServer = new VoiceCallServer({
  port: process.env.PORT || 8082,
  httpsPort: process.env.HTTPS_PORT || 8443
});

// çµ±è¨ˆãƒ­ã‚°å‡ºåŠ›ï¼ˆ5åˆ†ã”ã¨ï¼‰
setInterval(() => {
  console.log('ğŸ“Š Server Stats:', voiceServer.getStats());
}, 5 * 60 * 1000);

module.exports = VoiceCallServer;