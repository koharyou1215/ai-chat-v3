// src/components/voice/VoiceCallTest.tsx
// æ®µéšçš„ã«ãƒ†ã‚¹ãƒˆã§ãã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

import React, { useState, useRef, useEffect } from 'react';
import { Phone, Mic, Volume2, CheckCircle, XCircle, Loader } from 'lucide-react';

export const VoiceCallTest: React.FC = () => {
  const [testResults, setTestResults] = useState({
    webSocket: 'pending',
    microphone: 'pending',
    voicevox: 'pending',
    audioPlayback: 'pending'
  });
  
  const [logs, setLogs] = useState<string[]>([]);
  const [isConnected, setIsConnected] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  
  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  
  // ãƒ­ã‚°è¿½åŠ é–¢æ•°
  const addLog = (message: string) => {
    const timestamp = new Date().toLocaleTimeString();
    setLogs(prev => [...prev, `[${timestamp}] ${message}`]);
    console.log(`[VoiceTest] ${message}`);
  };
  
  // 1. WebSocketæ¥ç¶šãƒ†ã‚¹ãƒˆ
  const testWebSocket = async () => {
    addLog('WebSocketæ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹...');
    setTestResults(prev => ({ ...prev, webSocket: 'testing' }));
    
    try {
      const ws = new WebSocket('ws://localhost:8082');
      
      ws.onopen = () => {
        addLog('âœ… WebSocketæ¥ç¶šæˆåŠŸ');
        setIsConnected(true);
        setTestResults(prev => ({ ...prev, webSocket: 'success' }));
        wsRef.current = ws;
        
        // ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
        ws.send(JSON.stringify({ type: 'test' }));
      };
      
      ws.onmessage = (event) => {
        if (event.data instanceof Blob) {
          addLog(`ğŸ“¨ éŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ä¿¡: ${event.data.size} bytes`);
          playAudioBlob(event.data);
        } else {
          try {
            const message = JSON.parse(event.data);
            addLog(`ğŸ“¨ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡: ${message.type}`);
            
            if (message.type === 'test_response') {
              addLog('âœ… ãƒ†ã‚¹ãƒˆå¿œç­”å—ä¿¡æˆåŠŸ');
              setTestResults(prev => ({ ...prev, voicevox: 'success' }));
            }
          } catch (error) {
            addLog(`âš ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: ${error}`);
          }
        }
      };
      
      ws.onerror = (error) => {
        addLog(`âŒ WebSocketã‚¨ãƒ©ãƒ¼: ${error}`);
        setTestResults(prev => ({ ...prev, webSocket: 'error' }));
      };
      
      ws.onclose = () => {
        addLog('WebSocketåˆ‡æ–­');
        setIsConnected(false);
      };
      
    } catch (error) {
      addLog(`âŒ WebSocketæ¥ç¶šå¤±æ•—: ${error}`);
      setTestResults(prev => ({ ...prev, webSocket: 'error' }));
    }
  };
  
  // 2. ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆ
  const testMicrophone = async () => {
    addLog('ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹...');
    setTestResults(prev => ({ ...prev, microphone: 'testing' }));
    
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 16000,
          echoCancellation: true,
          noiseSuppression: true
        }
      });
      
      mediaStreamRef.current = stream;
      addLog('âœ… ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ');
      setTestResults(prev => ({ ...prev, microphone: 'success' }));
      
      // AudioContextã§ãƒ†ã‚¹ãƒˆéŒ²éŸ³
      audioContextRef.current = new AudioContext({ sampleRate: 16000 });
      const source = audioContextRef.current.createMediaStreamSource(stream);
      const processor = audioContextRef.current.createScriptProcessor(512, 1, 1);
      
      let sampleCount = 0;
      processor.onaudioprocess = (e) => {
        if (isRecording && wsRef.current?.readyState === WebSocket.OPEN) {
          const inputData = e.inputBuffer.getChannelData(0);
          const buffer = new ArrayBuffer(inputData.length * 2);
          const view = new DataView(buffer);
          
          for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]));
            view.setInt16(i * 2, s * 0x7FFF, true);
          }
          
          wsRef.current.send(buffer);
          sampleCount++;
          
          // 100ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«ãƒ­ã‚°
          if (sampleCount % 100 === 0) {
            addLog(`ğŸ¤ éŸ³å£°é€ä¿¡ä¸­... (${sampleCount} chunks)`);
          }
        }
      };
      
      source.connect(processor);
      processor.connect(audioContextRef.current.destination);
      
    } catch (error) {
      addLog(`âŒ ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: ${error}`);
      setTestResults(prev => ({ ...prev, microphone: 'error' }));
    }
  };
  
  // 3. éŸ³å£°å†ç”Ÿãƒ†ã‚¹ãƒˆ
  const playAudioBlob = async (blob: Blob) => {
    try {
      if (!audioContextRef.current) {
        audioContextRef.current = new AudioContext();
      }
      
      const arrayBuffer = await blob.arrayBuffer();
      const audioBuffer = await audioContextRef.current.decodeAudioData(arrayBuffer);
      
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);
      source.start();
      
      addLog('âœ… éŸ³å£°å†ç”ŸæˆåŠŸ');
      setTestResults(prev => ({ ...prev, audioPlayback: 'success' }));
      
    } catch (error) {
      addLog(`âŒ éŸ³å£°å†ç”Ÿå¤±æ•—: ${error}`);
      setTestResults(prev => ({ ...prev, audioPlayback: 'error' }));
    }
  };
  
  // 4. VOICEVOXãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆãƒ†ã‚¹ãƒˆ
  const testVoicevoxDirect = async () => {
    addLog('VOICEVOXç›´æ¥ãƒ†ã‚¹ãƒˆé–‹å§‹...');
    
    try {
      // ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ä¸€è¦§å–å¾—
      const speakersResponse = await fetch('http://127.0.0.1:50021/speakers');
      const speakers = await speakersResponse.json();
      addLog(`âœ… VOICEVOXæ¥ç¶šæˆåŠŸ: ${speakers.length} speakers available`);
      
      // ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆ
      const text = 'ãƒ†ã‚¹ãƒˆéŸ³å£°ã§ã™';
      const queryResponse = await fetch('http://127.0.0.1:50021/audio_query?speaker=1', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(text)
      });
      const queryData = await queryResponse.json();
      
      const synthesisResponse = await fetch('http://127.0.0.1:50021/synthesis?speaker=1', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(queryData)
      });
      
      const audioBlob = await synthesisResponse.blob();
      addLog(`âœ… VOICEVOXéŸ³å£°ç”ŸæˆæˆåŠŸ: ${audioBlob.size} bytes`);
      
      // å†ç”Ÿ
      const audio = new Audio(URL.createObjectURL(audioBlob));
      await audio.play();
      
    } catch (error) {
      addLog(`âŒ VOICEVOXãƒ†ã‚¹ãƒˆå¤±æ•—: ${error}`);
    }
  };
  
  // éŒ²éŸ³é–‹å§‹/åœæ­¢
  const toggleRecording = () => {
    if (isRecording) {
      addLog('ğŸ›‘ éŒ²éŸ³åœæ­¢');
      setIsRecording(false);
    } else {
      addLog('ğŸ¤ éŒ²éŸ³é–‹å§‹');
      setIsRecording(true);
    }
  };
  
  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  const cleanup = () => {
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
    }
    if (wsRef.current) {
      wsRef.current.close();
    }
  };
  
  useEffect(() => {
    return cleanup;
  }, []);
  
  // ãƒ†ã‚¹ãƒˆçµæœã®ã‚¢ã‚¤ã‚³ãƒ³
  const getStatusIcon = (status: string) => {
    switch (status) {
      case 'success':
        return <CheckCircle className="text-green-500" size={20} />;
      case 'error':
        return <XCircle className="text-red-500" size={20} />;
      case 'testing':
        return <Loader className="text-blue-500 animate-spin" size={20} />;
      default:
        return <div className="w-5 h-5 rounded-full bg-gray-400" />;
    }
  };
  
  return (
    <div className="p-6 max-w-4xl mx-auto">
      <h2 className="text-2xl font-bold mb-6">éŸ³å£°é€šè©±æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ</h2>
      
      {/* ãƒ†ã‚¹ãƒˆçµæœ */}
      <div className="grid grid-cols-2 gap-4 mb-6">
        <div className="p-4 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="flex items-center justify-between mb-2">
            <span>WebSocketæ¥ç¶š</span>
            {getStatusIcon(testResults.webSocket)}
          </div>
          <button
            onClick={testWebSocket}
            className="w-full px-3 py-2 bg-blue-500 text-white rounded hover:bg-blue-600"
          >
            æ¥ç¶šãƒ†ã‚¹ãƒˆ
          </button>
        </div>
        
        <div className="p-4 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="flex items-center justify-between mb-2">
            <span>ãƒã‚¤ã‚¯</span>
            {getStatusIcon(testResults.microphone)}
          </div>
          <button
            onClick={testMicrophone}
            disabled={!isConnected}
            className="w-full px-3 py-2 bg-blue-500 text-white rounded hover:bg-blue-600 disabled:opacity-50"
          >
            ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆ
          </button>
        </div>
        
        <div className="p-4 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="flex items-center justify-between mb-2">
            <span>VOICEVOX</span>
            {getStatusIcon(testResults.voicevox)}
          </div>
          <button
            onClick={testVoicevoxDirect}
            className="w-full px-3 py-2 bg-blue-500 text-white rounded hover:bg-blue-600"
          >
            ç›´æ¥ãƒ†ã‚¹ãƒˆ
          </button>
        </div>
        
        <div className="p-4 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="flex items-center justify-between mb-2">
            <span>éŸ³å£°å†ç”Ÿ</span>
            {getStatusIcon(testResults.audioPlayback)}
          </div>
          <div className="text-sm text-gray-600">
            éŸ³å£°å—ä¿¡æ™‚ã«è‡ªå‹•ãƒ†ã‚¹ãƒˆ
          </div>
        </div>
      </div>
      
      {/* éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« */}
      <div className="mb-6">
        <button
          onClick={toggleRecording}
          disabled={!isConnected || testResults.microphone !== 'success'}
          className={`px-6 py-3 rounded-lg font-medium transition-colors ${
            isRecording 
              ? 'bg-red-500 text-white hover:bg-red-600' 
              : 'bg-green-500 text-white hover:bg-green-600'
          } disabled:opacity-50`}
        >
          {isRecording ? 'ğŸ›‘ éŒ²éŸ³åœæ­¢' : 'ğŸ¤ éŒ²éŸ³é–‹å§‹'}
        </button>
        
        {isRecording && (
          <span className="ml-4 text-red-500 animate-pulse">
            â— éŒ²éŸ³ä¸­...
          </span>
        )}
      </div>
      
      {/* ãƒ­ã‚°è¡¨ç¤º */}
      <div className="bg-black text-green-400 p-4 rounded-lg font-mono text-sm h-64 overflow-y-auto">
        {logs.map((log, index) => (
          <div key={index}>{log}</div>
        ))}
        {logs.length === 0 && (
          <div className="text-gray-600">ãƒ­ã‚°ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™...</div>
        )}
      </div>
      
      {/* ã‚µãƒ¼ãƒãƒ¼æƒ…å ± */}
      <div className="mt-4 text-sm text-gray-600">
        <p>WebSocketã‚µãƒ¼ãƒãƒ¼: ws://localhost:8082</p>
        <p>VOICEVOX: http://127.0.0.1:50021</p>
        <p>æ¥ç¶šçŠ¶æ…‹: {isConnected ? 'âœ… æ¥ç¶šä¸­' : 'âŒ æœªæ¥ç¶š'}</p>
      </div>
    </div>
  );
};